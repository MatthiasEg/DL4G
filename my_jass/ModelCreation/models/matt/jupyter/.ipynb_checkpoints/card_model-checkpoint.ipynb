{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trump Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow \n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define paths to data files\n",
    "path_to_train_data = Path(\"C:\\\\Users\\\\matth\\\\Documents\\\\DL4G\\\\jass-data\\\\split\\\\train\\\\filtered\\\\card\\\\csv\")\n",
    "path_to_test_data = Path(\"C:\\\\Users\\\\matth\\\\Documents\\\\DL4G\\\\jass-data\\\\split\\\\test\\\\filtered\\\\card\\\\csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "data_train1 = pd.read_csv(path_to_train_data / '0001.csv', header=None)\n",
    "data_train2 = pd.read_csv(path_to_train_data / '0002.csv', header=None)\n",
    "data_train3 = pd.read_csv(path_to_train_data / '0003.csv', header=None)\n",
    "data_train4 = pd.read_csv(path_to_train_data / '0004.csv', header=None)\n",
    "\n",
    "data_train = pd.concat([data_train1, data_train2, data_train3, data_train4], axis=0)\n",
    "data_train.shape\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "data_test1 = pd.read_csv(path_to_test_data / '0001.csv', header=None)\n",
    "data_test2 = pd.read_csv(path_to_train_data / '0002.csv', header=None)\n",
    "\n",
    "data_test = pd.concat([data_test1, data_test2])\n",
    "data_test.shape\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label data for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare x and y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colums used for extracting x and y values. The same effect could be achieved with train_test_split-Method, but \n",
    "# since we already have different files, we dont need to split the files using this method.\n",
    "#data_X_columns = cards + forehand\n",
    "#data_Y_colums = trump\n",
    "\n",
    "x_train = data_train[data_train.columns[0:81]]\n",
    "y_train = data_train[data_train.columns[82]]\n",
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "\n",
    "x_test = data_test[data_test.columns[0:81]]\n",
    "y_test = data_test[data_test.columns[82]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 37 features, so we have a node for each feature. There are 7 output categories: each trump color(4), \n",
    "# obe-abe, unde-ufe, schiebe. So we need an reducing function with 7 elements\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(81, activation='relu', input_shape=[81]))\n",
    "model.add(keras.layers.Dense(81, activation='relu'))\n",
    "model.add(keras.layers.Dense(81, activation='relu', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(81, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(81, activation='relu'))\n",
    "model.add(keras.layers.Dense(36, activation='softmax'))\n",
    "\n",
    "opt = Adam()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to convert the y_train to a array with 7 elements, to represent each \n",
    "# of the 7 categories\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "\n",
    "history = model.fit(x_train, y_train_categorical, epochs=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate graphs for loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['Train'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_categorical = to_categorical(y_test)\n",
    "model.evaluate(x_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"card_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
