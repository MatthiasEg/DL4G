{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trump Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define paths to data files\n",
    "path_to_train_data = Path(\"C:\\\\Users\\\\matth\\\\Documents\\\\DL4G\\\\jass-data\\\\split\\\\train\\\\filtered\\\\card\\\\csv\")\n",
    "path_to_test_data = Path(\"C:\\\\Users\\\\matth\\\\Documents\\\\DL4G\\\\jass-data\\\\split\\\\test\\\\filtered\\\\card\\\\csv\")\n",
    "path_to_val_data = Path(\"C:\\\\Users\\\\matth\\\\Documents\\\\DL4G\\\\jass-data\\\\split\\\\val\\\\filtered\\\\card\\\\csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "data_train1 = pd.read_csv(path_to_train_data / '0001.csv', header=None)\n",
    "data_train2 = pd.read_csv(path_to_train_data / '0002.csv', header=None)\n",
    "data_train3 = pd.read_csv(path_to_train_data / '0003.csv', header=None)\n",
    "data_train4 = pd.read_csv(path_to_train_data / '0004.csv', header=None)\n",
    "data_val1 = pd.read_csv(path_to_val_data / '0001.csv', header=None)\n",
    "data_val2 = pd.read_csv(path_to_val_data / '0002.csv', header=None)\n",
    "\n",
    "data_train = pd.concat([data_train1, data_train2, data_train3, data_train4, data_val1, data_val2], axis=0)\n",
    "#data_val = pd.concat([data_val1, data_val2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  73  74  75  76  77  78  79  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   0   1   \n",
       "1   1   1   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   1   0   \n",
       "2   0   0   0   0   0   0   0   0   0   0  ...   0   0   1   0   0   0   1   \n",
       "3   0   0   0   1   0   1   0   1   0   0  ...   0   0   1   0   0   0   0   \n",
       "4   0   1   0   0   0   1   0   0   1   0  ...   0   0   1   0   0   0   1   \n",
       "\n",
       "   80  81  82  \n",
       "0   0   0  21  \n",
       "1   0   0  20  \n",
       "2   0   0  12  \n",
       "3   0   1   3  \n",
       "4   0   0   8  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "data_test1 = pd.read_csv(path_to_test_data / '0001.csv', header=None)\n",
    "data_test2 = pd.read_csv(path_to_train_data / '0002.csv', header=None)\n",
    "\n",
    "data_test = pd.concat([data_test1, data_test2])\n",
    "data_test.shape\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label data for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare x and y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colums used for extracting x and y values. The same effect could be achieved with train_test_split-Method, but \n",
    "# since we already have different files, we dont need to split the files using this method.\n",
    "#data_X_columns = cards + forehand\n",
    "#data_Y_colums = trump\n",
    "\n",
    "x_train = data_train[data_train.columns[0:82]]\n",
    "y_train = data_train[data_train.columns[82]]\n",
    "#print (x_train.head())\n",
    "#print (y_train.head())\n",
    "\n",
    "x_test = data_test[data_test.columns[0:82]]\n",
    "y_test = data_test[data_test.columns[82]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 82)                6806      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 82)                6806      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 82)                6806      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 82)                6806      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 82)                6806      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 82)                6806      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 36)                2988      \n",
      "=================================================================\n",
      "Total params: 43,824\n",
      "Trainable params: 43,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# We have 37 features, so we have a node for each feature. There are 7 output categories: each trump color(4), \n",
    "# obe-abe, unde-ufe, schiebe. So we need an reducing function with 7 elements\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(82, activation='relu', input_shape=[82]))\n",
    "model.add(keras.layers.Dense(82, activation='relu'))\n",
    "model.add(keras.layers.Dense(82, activation='relu', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(82, activation='relu'))\n",
    "model.add(keras.layers.Dense(82, activation='relu'))\n",
    "model.add(keras.layers.Dense(82, activation='relu'))\n",
    "model.add(keras.layers.Dense(36, activation='softmax'))\n",
    "\n",
    "opt = Adam()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 408132 samples, validate on 102033 samples\n",
      "Epoch 1/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 1.9281 - accuracy: 0.4238 - val_loss: 1.5377 - val_accuracy: 0.4990\n",
      "Epoch 2/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 1.4542 - accuracy: 0.5206 - val_loss: 1.4073 - val_accuracy: 0.5324\n",
      "Epoch 3/150\n",
      "408132/408132 [==============================] - 16s 40us/sample - loss: 1.3558 - accuracy: 0.5437 - val_loss: 1.3135 - val_accuracy: 0.5517\n",
      "Epoch 4/150\n",
      "408132/408132 [==============================] - 21s 51us/sample - loss: 1.2980 - accuracy: 0.5564 - val_loss: 1.3079 - val_accuracy: 0.5466\n",
      "Epoch 5/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 1.2554 - accuracy: 0.5666 - val_loss: 1.2474 - val_accuracy: 0.5694\n",
      "Epoch 6/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 1.2215 - accuracy: 0.5760 - val_loss: 1.2191 - val_accuracy: 0.5754\n",
      "Epoch 7/150\n",
      "408132/408132 [==============================] - 16s 38us/sample - loss: 1.1925 - accuracy: 0.5822 - val_loss: 1.1948 - val_accuracy: 0.5792\n",
      "Epoch 8/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 1.1693 - accuracy: 0.5883 - val_loss: 1.1776 - val_accuracy: 0.5862\n",
      "Epoch 9/150\n",
      "408132/408132 [==============================] - 17s 41us/sample - loss: 1.1509 - accuracy: 0.5933 - val_loss: 1.1635 - val_accuracy: 0.5847\n",
      "Epoch 10/150\n",
      "408132/408132 [==============================] - 14s 34us/sample - loss: 1.1332 - accuracy: 0.5974 - val_loss: 1.1694 - val_accuracy: 0.5891\n",
      "Epoch 11/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 1.1172 - accuracy: 0.6001 - val_loss: 1.1195 - val_accuracy: 0.5996\n",
      "Epoch 12/150\n",
      "408132/408132 [==============================] - 17s 43us/sample - loss: 1.1048 - accuracy: 0.6029 - val_loss: 1.1098 - val_accuracy: 0.5982\n",
      "Epoch 13/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 1.0912 - accuracy: 0.6049 - val_loss: 1.1064 - val_accuracy: 0.5983\n",
      "Epoch 14/150\n",
      "408132/408132 [==============================] - 14s 34us/sample - loss: 1.0786 - accuracy: 0.6065 - val_loss: 1.0828 - val_accuracy: 0.6027\n",
      "Epoch 15/150\n",
      "408132/408132 [==============================] - 15s 38us/sample - loss: 1.0666 - accuracy: 0.6092 - val_loss: 1.0881 - val_accuracy: 0.6040\n",
      "Epoch 16/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 1.0565 - accuracy: 0.6106 - val_loss: 1.0666 - val_accuracy: 0.6065\n",
      "Epoch 17/150\n",
      "408132/408132 [==============================] - 14s 33us/sample - loss: 1.0458 - accuracy: 0.6132 - val_loss: 1.0741 - val_accuracy: 0.6029\n",
      "Epoch 18/150\n",
      "408132/408132 [==============================] - 13s 32us/sample - loss: 1.0361 - accuracy: 0.6137 - val_loss: 1.0493 - val_accuracy: 0.6091\n",
      "Epoch 19/150\n",
      "408132/408132 [==============================] - 14s 33us/sample - loss: 1.0260 - accuracy: 0.6161 - val_loss: 1.0473 - val_accuracy: 0.6040\n",
      "Epoch 20/150\n",
      "408132/408132 [==============================] - 13s 32us/sample - loss: 1.0162 - accuracy: 0.6169 - val_loss: 1.0306 - val_accuracy: 0.6096\n",
      "Epoch 21/150\n",
      "408132/408132 [==============================] - 14s 34us/sample - loss: 1.0087 - accuracy: 0.6183 - val_loss: 1.0356 - val_accuracy: 0.6067\n",
      "Epoch 22/150\n",
      "408132/408132 [==============================] - 16s 40us/sample - loss: 1.0003 - accuracy: 0.6188 - val_loss: 1.0235 - val_accuracy: 0.6090\n",
      "Epoch 23/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.9912 - accuracy: 0.6199 - val_loss: 1.0111 - val_accuracy: 0.6138\n",
      "Epoch 24/150\n",
      "408132/408132 [==============================] - 14s 34us/sample - loss: 0.9827 - accuracy: 0.6213 - val_loss: 0.9982 - val_accuracy: 0.6174\n",
      "Epoch 25/150\n",
      "408132/408132 [==============================] - 14s 33us/sample - loss: 0.9760 - accuracy: 0.6225 - val_loss: 1.0005 - val_accuracy: 0.6138\n",
      "Epoch 26/150\n",
      "408132/408132 [==============================] - 13s 33us/sample - loss: 0.9683 - accuracy: 0.6232 - val_loss: 0.9940 - val_accuracy: 0.6139\n",
      "Epoch 27/150\n",
      "408132/408132 [==============================] - 14s 33us/sample - loss: 0.9620 - accuracy: 0.6249 - val_loss: 0.9810 - val_accuracy: 0.6146\n",
      "Epoch 28/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.9556 - accuracy: 0.6255 - val_loss: 0.9861 - val_accuracy: 0.6157\n",
      "Epoch 29/150\n",
      "408132/408132 [==============================] - 14s 33us/sample - loss: 0.9506 - accuracy: 0.6274 - val_loss: 0.9809 - val_accuracy: 0.6167\n",
      "Epoch 30/150\n",
      "408132/408132 [==============================] - 14s 36us/sample - loss: 0.9465 - accuracy: 0.6273 - val_loss: 0.9764 - val_accuracy: 0.6144\n",
      "Epoch 31/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.9421 - accuracy: 0.6290 - val_loss: 0.9804 - val_accuracy: 0.6179\n",
      "Epoch 32/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.9377 - accuracy: 0.6298 - val_loss: 0.9579 - val_accuracy: 0.6218\n",
      "Epoch 33/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.9336 - accuracy: 0.6302 - val_loss: 0.9585 - val_accuracy: 0.6222\n",
      "Epoch 34/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.9299 - accuracy: 0.6313 - val_loss: 0.9527 - val_accuracy: 0.6227\n",
      "Epoch 35/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.9280 - accuracy: 0.6324 - val_loss: 0.9600 - val_accuracy: 0.6235\n",
      "Epoch 36/150\n",
      "408132/408132 [==============================] - 16s 38us/sample - loss: 0.9226 - accuracy: 0.6335 - val_loss: 0.9521 - val_accuracy: 0.6221\n",
      "Epoch 37/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.9212 - accuracy: 0.6344 - val_loss: 0.9701 - val_accuracy: 0.6186\n",
      "Epoch 38/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 0.9183 - accuracy: 0.6341 - val_loss: 0.9623 - val_accuracy: 0.6205\n",
      "Epoch 39/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 0.9161 - accuracy: 0.6343 - val_loss: 0.9424 - val_accuracy: 0.6240\n",
      "Epoch 40/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.9136 - accuracy: 0.6365 - val_loss: 0.9410 - val_accuracy: 0.6261\n",
      "Epoch 41/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.9109 - accuracy: 0.6359 - val_loss: 0.9477 - val_accuracy: 0.6246\n",
      "Epoch 42/150\n",
      "408132/408132 [==============================] - 16s 40us/sample - loss: 0.9090 - accuracy: 0.6373 - val_loss: 0.9443 - val_accuracy: 0.6260\n",
      "Epoch 43/150\n",
      "408132/408132 [==============================] - 16s 38us/sample - loss: 0.9060 - accuracy: 0.6374 - val_loss: 0.9386 - val_accuracy: 0.6257\n",
      "Epoch 44/150\n",
      "408132/408132 [==============================] - 16s 40us/sample - loss: 0.9048 - accuracy: 0.6375 - val_loss: 0.9283 - val_accuracy: 0.6307\n",
      "Epoch 45/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.9035 - accuracy: 0.6374 - val_loss: 0.9326 - val_accuracy: 0.6290\n",
      "Epoch 46/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.9013 - accuracy: 0.6388 - val_loss: 0.9356 - val_accuracy: 0.6282\n",
      "Epoch 47/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8994 - accuracy: 0.6393 - val_loss: 0.9368 - val_accuracy: 0.6260\n",
      "Epoch 48/150\n",
      "408132/408132 [==============================] - 15s 38us/sample - loss: 0.8968 - accuracy: 0.6399 - val_loss: 0.9322 - val_accuracy: 0.6276\n",
      "Epoch 49/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 0.8949 - accuracy: 0.6405 - val_loss: 0.9372 - val_accuracy: 0.6275\n",
      "Epoch 50/150\n",
      "408132/408132 [==============================] - 17s 43us/sample - loss: 0.8931 - accuracy: 0.6407 - val_loss: 0.9357 - val_accuracy: 0.6282\n",
      "Epoch 51/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8921 - accuracy: 0.6415 - val_loss: 0.9310 - val_accuracy: 0.6282\n",
      "Epoch 52/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.8896 - accuracy: 0.6430 - val_loss: 0.9314 - val_accuracy: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8879 - accuracy: 0.6430 - val_loss: 0.9237 - val_accuracy: 0.6307\n",
      "Epoch 54/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.8859 - accuracy: 0.6439 - val_loss: 0.9271 - val_accuracy: 0.6301\n",
      "Epoch 55/150\n",
      "408132/408132 [==============================] - 16s 38us/sample - loss: 0.8857 - accuracy: 0.6432 - val_loss: 0.9132 - val_accuracy: 0.6315\n",
      "Epoch 56/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 0.8828 - accuracy: 0.6444 - val_loss: 0.9287 - val_accuracy: 0.6323\n",
      "Epoch 57/150\n",
      "408132/408132 [==============================] - 13s 33us/sample - loss: 0.8826 - accuracy: 0.6440 - val_loss: 0.9229 - val_accuracy: 0.6291\n",
      "Epoch 58/150\n",
      "408132/408132 [==============================] - 13s 32us/sample - loss: 0.8806 - accuracy: 0.6447 - val_loss: 0.9410 - val_accuracy: 0.6288\n",
      "Epoch 59/150\n",
      "408132/408132 [==============================] - 13s 32us/sample - loss: 0.8789 - accuracy: 0.6456 - val_loss: 0.9131 - val_accuracy: 0.6329\n",
      "Epoch 60/150\n",
      "408132/408132 [==============================] - 15s 38us/sample - loss: 0.8778 - accuracy: 0.6467 - val_loss: 0.9107 - val_accuracy: 0.6345\n",
      "Epoch 61/150\n",
      "408132/408132 [==============================] - 16s 40us/sample - loss: 0.8770 - accuracy: 0.6466 - val_loss: 0.9180 - val_accuracy: 0.6307\n",
      "Epoch 62/150\n",
      "408132/408132 [==============================] - 15s 38us/sample - loss: 0.8758 - accuracy: 0.6471 - val_loss: 0.9067 - val_accuracy: 0.6370\n",
      "Epoch 63/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.8743 - accuracy: 0.6468 - val_loss: 0.9128 - val_accuracy: 0.6336\n",
      "Epoch 64/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 0.8738 - accuracy: 0.6469 - val_loss: 0.9008 - val_accuracy: 0.6346\n",
      "Epoch 65/150\n",
      "408132/408132 [==============================] - 16s 40us/sample - loss: 0.8703 - accuracy: 0.6476 - val_loss: 0.9154 - val_accuracy: 0.6357\n",
      "Epoch 66/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 0.8712 - accuracy: 0.6488 - val_loss: 0.9185 - val_accuracy: 0.6341\n",
      "Epoch 67/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8693 - accuracy: 0.6488 - val_loss: 0.9111 - val_accuracy: 0.6330\n",
      "Epoch 68/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 0.8681 - accuracy: 0.6497 - val_loss: 0.9079 - val_accuracy: 0.6352\n",
      "Epoch 69/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8663 - accuracy: 0.6490 - val_loss: 0.9105 - val_accuracy: 0.6374\n",
      "Epoch 70/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 0.8645 - accuracy: 0.6500 - val_loss: 0.9033 - val_accuracy: 0.6378\n",
      "Epoch 71/150\n",
      "408132/408132 [==============================] - 14s 34us/sample - loss: 0.8656 - accuracy: 0.6502 - val_loss: 0.8948 - val_accuracy: 0.6409\n",
      "Epoch 72/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8621 - accuracy: 0.6514 - val_loss: 0.8942 - val_accuracy: 0.6375\n",
      "Epoch 73/150\n",
      "408132/408132 [==============================] - 14s 34us/sample - loss: 0.8616 - accuracy: 0.6511 - val_loss: 0.8927 - val_accuracy: 0.6374\n",
      "Epoch 74/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.8606 - accuracy: 0.6520 - val_loss: 0.8984 - val_accuracy: 0.6403\n",
      "Epoch 75/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8590 - accuracy: 0.6530 - val_loss: 0.8962 - val_accuracy: 0.6371\n",
      "Epoch 76/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8580 - accuracy: 0.6530 - val_loss: 0.8994 - val_accuracy: 0.6411\n",
      "Epoch 77/150\n",
      "408132/408132 [==============================] - 16s 40us/sample - loss: 0.8569 - accuracy: 0.6528 - val_loss: 0.8966 - val_accuracy: 0.6397\n",
      "Epoch 78/150\n",
      "408132/408132 [==============================] - 18s 43us/sample - loss: 0.8566 - accuracy: 0.6530 - val_loss: 0.8951 - val_accuracy: 0.6403\n",
      "Epoch 79/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8554 - accuracy: 0.6535 - val_loss: 0.8972 - val_accuracy: 0.6394\n",
      "Epoch 80/150\n",
      "408132/408132 [==============================] - 14s 36us/sample - loss: 0.8533 - accuracy: 0.6544 - val_loss: 0.8902 - val_accuracy: 0.6428\n",
      "Epoch 81/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8524 - accuracy: 0.6552 - val_loss: 0.8966 - val_accuracy: 0.6376\n",
      "Epoch 82/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 0.8531 - accuracy: 0.6550 - val_loss: 0.8921 - val_accuracy: 0.6387\n",
      "Epoch 83/150\n",
      "408132/408132 [==============================] - 18s 45us/sample - loss: 0.8510 - accuracy: 0.6550 - val_loss: 0.8963 - val_accuracy: 0.6389\n",
      "Epoch 84/150\n",
      "408132/408132 [==============================] - 20s 48us/sample - loss: 0.8506 - accuracy: 0.6557 - val_loss: 0.9024 - val_accuracy: 0.6382\n",
      "Epoch 85/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 0.8505 - accuracy: 0.6566 - val_loss: 0.8862 - val_accuracy: 0.6418\n",
      "Epoch 86/150\n",
      "408132/408132 [==============================] - 20s 48us/sample - loss: 0.8491 - accuracy: 0.6559 - val_loss: 0.8801 - val_accuracy: 0.6443\n",
      "Epoch 87/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 0.8486 - accuracy: 0.6568 - val_loss: 0.8927 - val_accuracy: 0.6434\n",
      "Epoch 88/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 0.8485 - accuracy: 0.6570 - val_loss: 0.8822 - val_accuracy: 0.6447\n",
      "Epoch 89/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 0.8476 - accuracy: 0.6568 - val_loss: 0.8873 - val_accuracy: 0.6421\n",
      "Epoch 90/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.8461 - accuracy: 0.6570 - val_loss: 0.8910 - val_accuracy: 0.6454\n",
      "Epoch 91/150\n",
      "408132/408132 [==============================] - 18s 45us/sample - loss: 0.8475 - accuracy: 0.6580 - val_loss: 0.8871 - val_accuracy: 0.6410\n",
      "Epoch 92/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8470 - accuracy: 0.6576 - val_loss: 0.8911 - val_accuracy: 0.6427\n",
      "Epoch 93/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.8453 - accuracy: 0.6569 - val_loss: 0.8816 - val_accuracy: 0.6463\n",
      "Epoch 94/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 0.8450 - accuracy: 0.6579 - val_loss: 0.8786 - val_accuracy: 0.6437\n",
      "Epoch 95/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 0.8446 - accuracy: 0.6579 - val_loss: 0.8801 - val_accuracy: 0.6442\n",
      "Epoch 96/150\n",
      "408132/408132 [==============================] - 16s 40us/sample - loss: 0.8438 - accuracy: 0.6578 - val_loss: 0.8788 - val_accuracy: 0.6470\n",
      "Epoch 97/150\n",
      "408132/408132 [==============================] - 18s 43us/sample - loss: 0.8436 - accuracy: 0.6589 - val_loss: 0.9029 - val_accuracy: 0.6420\n",
      "Epoch 98/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.8433 - accuracy: 0.6590 - val_loss: 0.8954 - val_accuracy: 0.6429\n",
      "Epoch 99/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 0.8421 - accuracy: 0.6597 - val_loss: 0.8843 - val_accuracy: 0.6444\n",
      "Epoch 100/150\n",
      "408132/408132 [==============================] - 18s 43us/sample - loss: 0.8422 - accuracy: 0.6590 - val_loss: 0.8990 - val_accuracy: 0.6386\n",
      "Epoch 101/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.8420 - accuracy: 0.6599 - val_loss: 0.8795 - val_accuracy: 0.6459\n",
      "Epoch 102/150\n",
      "408132/408132 [==============================] - 19s 47us/sample - loss: 0.8412 - accuracy: 0.6596 - val_loss: 0.8761 - val_accuracy: 0.6477\n",
      "Epoch 103/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 0.8415 - accuracy: 0.6593 - val_loss: 0.8858 - val_accuracy: 0.6436\n",
      "Epoch 104/150\n",
      "408132/408132 [==============================] - 16s 39us/sample - loss: 0.8420 - accuracy: 0.6599 - val_loss: 0.8797 - val_accuracy: 0.6472\n",
      "Epoch 105/150\n",
      "408132/408132 [==============================] - 20s 50us/sample - loss: 0.8414 - accuracy: 0.6606 - val_loss: 0.8759 - val_accuracy: 0.6448\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.8402 - accuracy: 0.6608 - val_loss: 0.8838 - val_accuracy: 0.6464\n",
      "Epoch 107/150\n",
      "408132/408132 [==============================] - 15s 38us/sample - loss: 0.8391 - accuracy: 0.6602 - val_loss: 0.8833 - val_accuracy: 0.6461\n",
      "Epoch 108/150\n",
      "408132/408132 [==============================] - 15s 36us/sample - loss: 0.8400 - accuracy: 0.6599 - val_loss: 0.8834 - val_accuracy: 0.6471\n",
      "Epoch 109/150\n",
      "408132/408132 [==============================] - 14s 34us/sample - loss: 0.8390 - accuracy: 0.6608 - val_loss: 0.8820 - val_accuracy: 0.6472\n",
      "Epoch 110/150\n",
      "408132/408132 [==============================] - 15s 37us/sample - loss: 0.8386 - accuracy: 0.6616 - val_loss: 0.8929 - val_accuracy: 0.6413\n",
      "Epoch 111/150\n",
      "408132/408132 [==============================] - 15s 38us/sample - loss: 0.8397 - accuracy: 0.6607 - val_loss: 0.8740 - val_accuracy: 0.6472\n",
      "Epoch 112/150\n",
      "408132/408132 [==============================] - 14s 34us/sample - loss: 0.8372 - accuracy: 0.6614 - val_loss: 0.8764 - val_accuracy: 0.6486\n",
      "Epoch 113/150\n",
      "408132/408132 [==============================] - 14s 33us/sample - loss: 0.8370 - accuracy: 0.6615 - val_loss: 0.8973 - val_accuracy: 0.6418\n",
      "Epoch 114/150\n",
      "408132/408132 [==============================] - 22s 54us/sample - loss: 0.8368 - accuracy: 0.6626 - val_loss: 0.8889 - val_accuracy: 0.6446\n",
      "Epoch 115/150\n",
      "151936/408132 [==========>...................] - ETA: 21s - loss: 0.8323 - accuracy: 0.6639"
     ]
    }
   ],
   "source": [
    "y_train_categorical = to_categorical(y_train)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train_categorical, validation_split=0.20, epochs=150, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate graphs for loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_categorical = to_categorical(y_test)\n",
    "model.evaluate(x_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"card_model_e120_b256_sgd.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
