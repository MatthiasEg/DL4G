{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trump Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define paths to data files\n",
    "path_to_train_data = Path(\"C:\\\\Users\\\\matth\\\\Documents\\\\DL4G\\\\jass-data\\\\split\\\\train\\\\filtered\\\\card\\\\csv\")\n",
    "path_to_test_data = Path(\"C:\\\\Users\\\\matth\\\\Documents\\\\DL4G\\\\jass-data\\\\split\\\\test\\\\filtered\\\\card\\\\csv\")\n",
    "path_to_val_data = Path(\"C:\\\\Users\\\\matth\\\\Documents\\\\DL4G\\\\jass-data\\\\split\\\\val\\\\filtered\\\\card\\\\csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "data_train1 = pd.read_csv(path_to_train_data / '0001.csv', header=None)\n",
    "data_train2 = pd.read_csv(path_to_train_data / '0002.csv', header=None)\n",
    "data_train3 = pd.read_csv(path_to_train_data / '0003.csv', header=None)\n",
    "data_train4 = pd.read_csv(path_to_train_data / '0004.csv', header=None)\n",
    "data_val1 = pd.read_csv(path_to_val_data / '0001.csv', header=None)\n",
    "data_val2 = pd.read_csv(path_to_val_data / '0002.csv', header=None)\n",
    "\n",
    "data_train = pd.concat([data_train1, data_train2, data_train3, data_train4, data_val1, data_val2], axis=0)\n",
    "#data_val = pd.concat([data_val1, data_val2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  73  74  75  76  77  78  79  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   0   1   \n",
       "1   1   1   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   1   0   \n",
       "2   0   0   0   0   0   0   0   0   0   0  ...   0   0   1   0   0   0   1   \n",
       "3   0   0   0   1   0   1   0   1   0   0  ...   0   0   1   0   0   0   0   \n",
       "4   0   1   0   0   0   1   0   0   1   0  ...   0   0   1   0   0   0   1   \n",
       "\n",
       "   80  81  82  \n",
       "0   0   0  21  \n",
       "1   0   0  20  \n",
       "2   0   0  12  \n",
       "3   0   1   3  \n",
       "4   0   0   8  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "data_test1 = pd.read_csv(path_to_test_data / '0001.csv', header=None)\n",
    "data_test2 = pd.read_csv(path_to_train_data / '0002.csv', header=None)\n",
    "\n",
    "data_test = pd.concat([data_test1, data_test2])\n",
    "data_test.shape\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label data for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare x and y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colums used for extracting x and y values. The same effect could be achieved with train_test_split-Method, but \n",
    "# since we already have different files, we dont need to split the files using this method.\n",
    "#data_X_columns = cards + forehand\n",
    "#data_Y_colums = trump\n",
    "\n",
    "x_train = data_train[data_train.columns[0:82]]\n",
    "y_train = data_train[data_train.columns[82]]\n",
    "#print (x_train.head())\n",
    "#print (y_train.head())\n",
    "\n",
    "x_test = data_test[data_test.columns[0:82]]\n",
    "y_test = data_test[data_test.columns[82]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 82)                6806      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 70)                5810      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 58)                4118      \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 58)                3422      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 46)                2714      \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 46)                2162      \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 36)                1692      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 36)                1332      \n",
      "=================================================================\n",
      "Total params: 33,026\n",
      "Trainable params: 33,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# We have 37 features, so we have a node for each feature. There are 7 output categories: each trump color(4), \n",
    "# obe-abe, unde-ufe, schiebe. So we need an reducing function with 7 elements\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(82, activation='relu', input_shape=[82]))\n",
    "model.add(keras.layers.Dense(70, activation='relu'))\n",
    "model.add(keras.layers.Dense(70, activation='relu'))\n",
    "model.add(keras.layers.Dense(58, activation='relu'))\n",
    "model.add(keras.layers.Dense(58, activation='relu'))\n",
    "model.add(keras.layers.Dense(46, activation='relu'))\n",
    "model.add(keras.layers.Dense(46, activation='relu'))\n",
    "model.add(keras.layers.Dense(36, activation='relu'))\n",
    "model.add(keras.layers.Dense(36, activation='softmax'))\n",
    "\n",
    "opt = Adam()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 408132 samples, validate on 102033 samples\n",
      "Epoch 1/150\n",
      "408132/408132 [==============================] - 18s 43us/sample - loss: 2.1200 - accuracy: 0.3725 - val_loss: 1.6963 - val_accuracy: 0.4724\n",
      "Epoch 2/150\n",
      "408132/408132 [==============================] - 14s 35us/sample - loss: 1.5626 - accuracy: 0.5031 - val_loss: 1.4849 - val_accuracy: 0.5183\n",
      "Epoch 3/150\n",
      "408132/408132 [==============================] - 17s 40us/sample - loss: 1.4124 - accuracy: 0.5344 - val_loss: 1.3699 - val_accuracy: 0.5368\n",
      "Epoch 4/150\n",
      "380800/408132 [==========================>...] - ETA: 1s - loss: 1.3286 - accuracy: 0.5515"
     ]
    }
   ],
   "source": [
    "y_train_categorical = to_categorical(y_train)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train_categorical, validation_split=0.20, epochs=150, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate graphs for loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_categorical = to_categorical(y_test)\n",
    "model.evaluate(x_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"card_model_e120_b256_sgd.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
