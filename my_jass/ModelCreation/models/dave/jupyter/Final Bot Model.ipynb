{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trump Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1833,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define paths to data files\n",
    "path_to_train_data = Path(\"C:/Users/gutda/pycharm_projects/jass-data/filtered_to_csv/train/\")\n",
    "path_to_test_data = Path(\"C:/Users/gutda/pycharm_projects/jass-data/filtered_to_csv/test/\")\n",
    "#path_to_val_data = Path(\"/Users/jabbathegut/PycharmProjects/DL4G/jass-demo/my_jass/models/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1834,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "data_train = pd.read_csv(path_to_train_data / 'filtered_data0001.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1835,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(path_to_test_data / 'filtered_data0001.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = 11999, 1 = 12325, 2 = 16495, 3 = 16178, 4 = 14856, 5 = 18270, 6 = 55951\n"
     ]
    }
   ],
   "source": [
    "data_train_f0 = (data_train[data_train[37]==0])\n",
    "data_train_f1 = (data_train[data_train[37]==1])\n",
    "data_train_f2 = (data_train[data_train[37]==2])\n",
    "data_train_f3 = (data_train[data_train[37]==3])\n",
    "data_train_f4 = (data_train[data_train[37]==4])\n",
    "data_train_f5 = (data_train[data_train[37]==5])\n",
    "data_train_f6 = (data_train[data_train[37]==6])\n",
    "\n",
    "print(f\"0 = {len(data_train_f0)}, 1 = {len(data_train_f1)}, 2 = {len(data_train_f2)}, 3 = {len(data_train_f3)}, 4 = {len(data_train_f4)}, 5 = {len(data_train_f5)}, 6 = {len(data_train_f6)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92883</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40604</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68142</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40773</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2   3   4   5   6   7   8   9   ...  28  29  30  31  32  33  \\\n",
       "92883   1   0   0   1   0   0   0   0   0   1  ...   0   0   0   0   0   0   \n",
       "40604   0   1   0   0   1   1   1   1   0   0  ...   0   0   0   0   0   1   \n",
       "68142   1   1   1   0   0   0   1   0   0   0  ...   0   0   1   0   1   0   \n",
       "77257   0   0   0   0   0   0   1   1   1   1  ...   0   0   0   0   1   1   \n",
       "40773   0   0   0   1   0   0   1   1   0   0  ...   0   0   1   0   0   0   \n",
       "\n",
       "       34  35  36  37  \n",
       "92883   1   0   0   4  \n",
       "40604   0   0   0   0  \n",
       "68142   0   1   0   3  \n",
       "77257   0   0   0   5  \n",
       "40773   0   0   0   0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 1837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_f0 = data_train_f0[0: 11000]\n",
    "data_train_f1 = data_train_f1[0: 11000]\n",
    "data_train_f2 = data_train_f2[0: 11000]\n",
    "data_train_f3 = data_train_f3[0: 11000]\n",
    "data_train_f4 = data_train_f4[0: 11000]\n",
    "data_train_f5 = data_train_f5[0: 11000]\n",
    "data_train_f6 = data_train_f6[0: 0] #don't train on schiebe\n",
    "\n",
    "data_train = pd.concat([data_train_f0, data_train_f1, data_train_f2, data_train_f3, data_train_f4, data_train_f5, data_train_f6])\n",
    "data_train = data_train.sample(frac=1)\n",
    "len(data_train)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = 3906, 1 = 4096, 2 = 5459, 3 = 5373, 4 = 4830, 5 = 6093, 6 = 18647\n"
     ]
    }
   ],
   "source": [
    "data_test_f0 = data_test[data_test[37]==0]\n",
    "data_test_f1 = data_test[data_test[37]==1]\n",
    "data_test_f2 = data_test[data_test[37]==2]\n",
    "data_test_f3 = data_test[data_test[37]==3]\n",
    "data_test_f4 = data_test[data_test[37]==4]\n",
    "data_test_f5 = data_test[data_test[37]==5]\n",
    "data_test_f6 = data_test[data_test[37]==6]\n",
    "\n",
    "print(f\"0 = {len(data_test_f0)}, 1 = {len(data_test_f1)}, 2 = {len(data_test_f2)}, 3 = {len(data_test_f3)}, 4 = {len(data_test_f4)}, 5 = {len(data_test_f5)}, 6 = {len(data_test_f6)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2   3   4   5   6   7   8   9   ...  28  29  30  31  32  33  \\\n",
       "4803    0   1   0   0   0   0   0   1   0   0  ...   1   0   0   1   1   0   \n",
       "1510    1   0   0   0   0   0   1   0   1   0  ...   1   0   0   1   0   0   \n",
       "4147    1   0   1   0   0   0   0   0   1   1  ...   0   0   0   0   1   1   \n",
       "12252   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "616     0   0   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   1   \n",
       "\n",
       "       34  35  36  37  \n",
       "4803    0   0   0   3  \n",
       "1510    0   1   0   5  \n",
       "4147    0   0   0   0  \n",
       "12252   0   0   0   1  \n",
       "616     0   0   0   2  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 1847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_f0 = data_test_f0[0:2200]\n",
    "data_test_f1 = data_test_f1[0:2000]\n",
    "data_test_f2 = data_test_f2[0:2000]\n",
    "data_test_f3 = data_test_f3[0:2000]\n",
    "data_test_f4 = data_test_f4[0:2000]\n",
    "data_test_f5 = data_test_f5[0:2000]\n",
    "data_test_f6 = data_test_f6[0:0] # change this value if output of 7 dimensions (with schiebe is needed)\n",
    "\n",
    "data_test = pd.concat([data_test_f0, data_test_f1, data_test_f2, data_test_f3, data_test_f4, data_test_f5, data_test_f6])\n",
    "data_test = data_test.sample(frac=1)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1784,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label data for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>DK</th>\n",
       "      <th>DQ</th>\n",
       "      <th>DJ</th>\n",
       "      <th>D10</th>\n",
       "      <th>D9</th>\n",
       "      <th>D8</th>\n",
       "      <th>D7</th>\n",
       "      <th>D6</th>\n",
       "      <th>HA</th>\n",
       "      <th>...</th>\n",
       "      <th>CK</th>\n",
       "      <th>CQ</th>\n",
       "      <th>CJ</th>\n",
       "      <th>C10</th>\n",
       "      <th>C9</th>\n",
       "      <th>C8</th>\n",
       "      <th>C7</th>\n",
       "      <th>C6</th>\n",
       "      <th>FH</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92883</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40604</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68142</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40773</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  CK  CQ  CJ  C10  C9  C8  \\\n",
       "92883   1   0   0   1    0   0   0   0   0   1  ...   0   0   0    0   0   0   \n",
       "40604   0   1   0   0    1   1   1   1   0   0  ...   0   0   0    0   0   1   \n",
       "68142   1   1   1   0    0   0   1   0   0   0  ...   0   0   1    0   1   0   \n",
       "77257   0   0   0   0    0   0   1   1   1   1  ...   0   0   0    0   1   1   \n",
       "40773   0   0   0   1    0   0   1   1   0   0  ...   0   0   1    0   0   0   \n",
       "\n",
       "       C7  C6  FH  trump  \n",
       "92883   1   0   0      4  \n",
       "40604   0   0   0      0  \n",
       "68142   0   1   0      3  \n",
       "77257   0   0   0      5  \n",
       "40773   0   0   0      0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 1848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add colums. Each card and the information \n",
    "# if the player played forehand or not is a feature. That means we have 37 features.\n",
    "# We also remove the player_id, because we do not care in the beginning\n",
    "\n",
    "cards = [\n",
    "# Diamonds\n",
    "'DA','DK','DQ','DJ','D10','D9','D8','D7','D6',\n",
    "# Hearts\n",
    "'HA','HK','HQ','HJ','H10','H9','H8','H7','H6',\n",
    "# Spades\n",
    "'SA','SK','SQ','SJ','S10','S9','S8','S7','S6',\n",
    "# Clubs\n",
    "'CA','CK','CQ','CJ','C10','C9','C8','C7','C6'\n",
    "]\n",
    "\n",
    "# Forehand (yes = 1, no = 0)\n",
    "forehand = ['FH']\n",
    "trump = ['trump']\n",
    "\n",
    "data_train.columns = cards + forehand + trump\n",
    "data_test.columns = cards + forehand  + trump\n",
    "#data_val.columns = cards + forehand + user + trump\n",
    "\n",
    "# remove user column\n",
    "#data_train.drop('user', axis='columns', inplace=True)\n",
    "#data_test.drop('user', axis='columns', inplace=True)\n",
    "#data_val.drop('user', axis='columns', inplace=True)\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data from files, eg. generate subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1849,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colums used for extracting x and y values. The same effect could be achieved with train_test_split-Method, but \n",
    "# since we already have different files, we dont need to split the files using this method.\n",
    "data_X_columns = cards + forehand\n",
    "data_Y_colums = trump\n",
    "\n",
    "x_train = data_train[data_X_columns]\n",
    "y_train = data_train[data_Y_colums]\n",
    "\n",
    "x_test = data_test[data_X_columns]\n",
    "y_test = data_test[data_Y_colums]\n",
    "\n",
    "#x_val = data_val[data_X_columns]\n",
    "#y_val = data_val[data_Y_colums]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_262\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1124 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1125 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1126 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1127 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1128 (Dense)           (None, 6)                 228       \n",
      "=================================================================\n",
      "Total params: 5,852\n",
      "Trainable params: 5,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# We have 37 features, so we have a node for each feature. There are 7 output categories: each trump color(4), \n",
    "# obe-abe, unde-ufe, schiebe. So we need an reducing function with 7 elements\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(37, activation='relu', input_shape=[37]))\n",
    "model.add(keras.layers.Dense(37, activation='relu'))\n",
    "model.add(keras.layers.Dense(37, activation='relu', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(37, activation='relu'))\n",
    "model.add(keras.layers.Dense(6, activation='softmax'))\n",
    "\n",
    "opt = Adam()\n",
    "\n",
    "# , kernel_regularizer=regularizers.l2(0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 66000 samples\n",
      "Epoch 1/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.9621 - accuracy: 0.6925\n",
      "Epoch 2/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.6012 - accuracy: 0.7950\n",
      "Epoch 3/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.5426 - accuracy: 0.8063\n",
      "Epoch 4/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.5095 - accuracy: 0.8140\n",
      "Epoch 5/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4903 - accuracy: 0.8177\n",
      "Epoch 6/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4771 - accuracy: 0.8214\n",
      "Epoch 7/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4677 - accuracy: 0.8229\n",
      "Epoch 8/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4623 - accuracy: 0.8256\n",
      "Epoch 9/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4578 - accuracy: 0.8268\n",
      "Epoch 10/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4556 - accuracy: 0.8263\n",
      "Epoch 11/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4490 - accuracy: 0.8292\n",
      "Epoch 12/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4502 - accuracy: 0.8269\n",
      "Epoch 13/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4467 - accuracy: 0.8301\n",
      "Epoch 14/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4442 - accuracy: 0.8294\n",
      "Epoch 15/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4429 - accuracy: 0.8300\n",
      "Epoch 16/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4425 - accuracy: 0.8286\n",
      "Epoch 17/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4406 - accuracy: 0.8310\n",
      "Epoch 18/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4388 - accuracy: 0.8313\n",
      "Epoch 19/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4382 - accuracy: 0.8312\n",
      "Epoch 20/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4353 - accuracy: 0.8312\n",
      "Epoch 21/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4350 - accuracy: 0.8329\n",
      "Epoch 22/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4344 - accuracy: 0.8332\n",
      "Epoch 23/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4337 - accuracy: 0.8330\n",
      "Epoch 24/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4312 - accuracy: 0.8328\n",
      "Epoch 25/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4304 - accuracy: 0.8337\n",
      "Epoch 26/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4303 - accuracy: 0.8334\n",
      "Epoch 27/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4295 - accuracy: 0.8342\n",
      "Epoch 28/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4290 - accuracy: 0.8340\n",
      "Epoch 29/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4267 - accuracy: 0.8343\n",
      "Epoch 30/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4267 - accuracy: 0.8355\n",
      "Epoch 31/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4268 - accuracy: 0.8336\n",
      "Epoch 32/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4263 - accuracy: 0.8346\n",
      "Epoch 33/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4237 - accuracy: 0.8363\n",
      "Epoch 34/100\n",
      "66000/66000 [==============================] - 1s 14us/sample - loss: 0.4247 - accuracy: 0.8335\n",
      "Epoch 35/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4238 - accuracy: 0.8352\n",
      "Epoch 36/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4226 - accuracy: 0.8363\n",
      "Epoch 37/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4225 - accuracy: 0.8370\n",
      "Epoch 38/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4206 - accuracy: 0.8366\n",
      "Epoch 39/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4214 - accuracy: 0.8357\n",
      "Epoch 40/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4201 - accuracy: 0.8365\n",
      "Epoch 41/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4202 - accuracy: 0.8373\n",
      "Epoch 42/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4193 - accuracy: 0.8373\n",
      "Epoch 43/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4202 - accuracy: 0.8361\n",
      "Epoch 44/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4164 - accuracy: 0.8393\n",
      "Epoch 45/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4184 - accuracy: 0.8362\n",
      "Epoch 46/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4177 - accuracy: 0.8375\n",
      "Epoch 47/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4180 - accuracy: 0.8375\n",
      "Epoch 48/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4165 - accuracy: 0.8382\n",
      "Epoch 49/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4153 - accuracy: 0.8391\n",
      "Epoch 50/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4149 - accuracy: 0.8383\n",
      "Epoch 51/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4154 - accuracy: 0.8385\n",
      "Epoch 52/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4146 - accuracy: 0.8383\n",
      "Epoch 53/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4132 - accuracy: 0.8392\n",
      "Epoch 54/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4140 - accuracy: 0.8388\n",
      "Epoch 55/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4140 - accuracy: 0.8395\n",
      "Epoch 56/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4120 - accuracy: 0.8398\n",
      "Epoch 57/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4114 - accuracy: 0.8377\n",
      "Epoch 58/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4132 - accuracy: 0.8377\n",
      "Epoch 59/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4115 - accuracy: 0.8398\n",
      "Epoch 60/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4105 - accuracy: 0.8398\n",
      "Epoch 61/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4105 - accuracy: 0.8387\n",
      "Epoch 62/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4093 - accuracy: 0.8389\n",
      "Epoch 63/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4099 - accuracy: 0.8403\n",
      "Epoch 64/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4092 - accuracy: 0.8402\n",
      "Epoch 65/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4086 - accuracy: 0.8389\n",
      "Epoch 66/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4092 - accuracy: 0.8400\n",
      "Epoch 67/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4079 - accuracy: 0.8404\n",
      "Epoch 68/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4072 - accuracy: 0.8404\n",
      "Epoch 69/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4071 - accuracy: 0.8391\n",
      "Epoch 70/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4078 - accuracy: 0.8400\n",
      "Epoch 71/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4068 - accuracy: 0.8404\n",
      "Epoch 72/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4061 - accuracy: 0.8403\n",
      "Epoch 73/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4064 - accuracy: 0.8413\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4056 - accuracy: 0.8421\n",
      "Epoch 75/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4064 - accuracy: 0.8396\n",
      "Epoch 76/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4054 - accuracy: 0.8408\n",
      "Epoch 77/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4047 - accuracy: 0.8412\n",
      "Epoch 78/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4055 - accuracy: 0.8406\n",
      "Epoch 79/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4044 - accuracy: 0.8412\n",
      "Epoch 80/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4049 - accuracy: 0.8405\n",
      "Epoch 81/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4034 - accuracy: 0.8425\n",
      "Epoch 82/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4041 - accuracy: 0.8412\n",
      "Epoch 83/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4035 - accuracy: 0.8418\n",
      "Epoch 84/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4041 - accuracy: 0.8416\n",
      "Epoch 85/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4041 - accuracy: 0.8410\n",
      "Epoch 86/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4031 - accuracy: 0.8415\n",
      "Epoch 87/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4031 - accuracy: 0.8422\n",
      "Epoch 88/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4016 - accuracy: 0.8414\n",
      "Epoch 89/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4029 - accuracy: 0.8422\n",
      "Epoch 90/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4028 - accuracy: 0.8422\n",
      "Epoch 91/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4021 - accuracy: 0.8425\n",
      "Epoch 92/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4016 - accuracy: 0.8425\n",
      "Epoch 93/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4011 - accuracy: 0.8424\n",
      "Epoch 94/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4011 - accuracy: 0.8413\n",
      "Epoch 95/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4012 - accuracy: 0.8420\n",
      "Epoch 96/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4008 - accuracy: 0.8423\n",
      "Epoch 97/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.3999 - accuracy: 0.8421\n",
      "Epoch 98/100\n",
      "66000/66000 [==============================] - 1s 13us/sample - loss: 0.4005 - accuracy: 0.8424\n",
      "Epoch 99/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4001 - accuracy: 0.8435\n",
      "Epoch 100/100\n",
      "66000/66000 [==============================] - 1s 12us/sample - loss: 0.4006 - accuracy: 0.8419\n"
     ]
    }
   ],
   "source": [
    "#log_dir=\"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# callback für tensor board\n",
    "#tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# we need to convert the y_train to a array with 7 elements, to represent each of the 7 categories\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "\n",
    "history = model.fit(x_train, y_train_categorical, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x249094df7c8>"
      ]
     },
     "execution_count": 1671,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['Train'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "12200/12200 [==============================] - 0s 17us/sample - loss: 0.4585 - accuracy: 0.8233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45854049380685463, 0.82327867]"
      ]
     },
     "execution_count": 1672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_categorical = to_categorical(y_test)\n",
    "model.evaluate(x_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1673,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "#model.save(\"final_model_82_games_025_mean_03_std_06.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_261\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1119 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1120 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1121 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1122 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1123 (Dense)           (None, 6)                 228       \n",
      "=================================================================\n",
      "Total params: 5,852\n",
      "Trainable params: 5,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('final_model_82_games_025_mean_03_std_06.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "12200/12200 [==============================] - 0s 16us/sample - loss: 0.4585 - accuracy: 0.8233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4585404926831605, 0.82327867]"
      ]
     },
     "execution_count": 1852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_categorical = to_categorical(y_test)\n",
    "model.evaluate(x_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1044 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1045 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1046 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1047 (Dense)           (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_1048 (Dense)           (None, 7)                 266       \n",
      "=================================================================\n",
      "Total params: 5,890\n",
      "Trainable params: 5,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('final_model_75_games_025_mean_03_std_06.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1850,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (12200, 6) was passed for an output of shape (None, 7) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1850-d74a359ae533>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_test_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_categorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\gutda\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    831\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m   def predict(self,\n",
      "\u001b[1;32mc:\\users\\gutda\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    695\u001b[0m     return test_loop(\n\u001b[0;32m    696\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gutda\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2536\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2538\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2540\u001b[0m       \u001b[1;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gutda\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    742\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (12200, 6) was passed for an output of shape (None, 7) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "y_test_categorical = to_categorical(y_test)\n",
    "model.evaluate(x_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
